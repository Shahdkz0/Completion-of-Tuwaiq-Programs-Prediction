{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9jWDfOaD7lP5"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('train.csv')"
      ],
      "metadata": {
        "id": "-4D5Ct7qYdUq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2- Data Exploration and Preprocessing"
      ],
      "metadata": {
        "id": "cbnYviqdZWao"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYkSHN8OdYMy",
        "outputId": "2b2c5f3c-44ce-47d6-b8ba-ee52d2209d2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Student ID                           0\n",
              "Age                                 92\n",
              "Gender                               0\n",
              "Home Region                          2\n",
              "Home City                            2\n",
              "Program ID                           0\n",
              "Program Main Category Code           0\n",
              "Program Sub Category Code          935\n",
              "Technology Type                   2982\n",
              "Program Skill Level               1646\n",
              "Program Presentation Method          0\n",
              "Program Start Date                   0\n",
              "Program End Date                     0\n",
              "Program Days                         0\n",
              "Completed Degree                     0\n",
              "Level of Education                  26\n",
              "Education Speaciality              277\n",
              "College                           3890\n",
              "University Degree Score             81\n",
              "University Degree Score System      81\n",
              "Employment Status                  566\n",
              "Job Type                          4567\n",
              "Still Working                     4567\n",
              "Y                                    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(['College', 'Job Type', 'Still Working', 'Home City', 'Home Region'], axis=1, inplace=True)\n"
      ],
      "metadata": {
        "id": "usSFm6V48LkG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdkIwekl8OwW",
        "outputId": "c48cc88e-a20d-4f28-ede7-016c0f96dc19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6548, 19)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ns93aYL89v-u",
        "outputId": "83b3501b-5505-4f7c-9637-7fd20815639b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Student ID                           0\n",
              "Age                                 92\n",
              "Gender                               0\n",
              "Program ID                           0\n",
              "Program Main Category Code           0\n",
              "Program Sub Category Code          935\n",
              "Technology Type                   2982\n",
              "Program Skill Level               1646\n",
              "Program Presentation Method          0\n",
              "Program Start Date                   0\n",
              "Program End Date                     0\n",
              "Program Days                         0\n",
              "Completed Degree                     0\n",
              "Level of Education                  26\n",
              "Education Speaciality              277\n",
              "University Degree Score             81\n",
              "University Degree Score System      81\n",
              "Employment Status                  566\n",
              "Y                                    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
        "df['University Degree Score'].fillna(df['University Degree Score'].mean(), inplace=True)\n",
        "\n",
        "df['University Degree Score System'].fillna(5, inplace=True)\n"
      ],
      "metadata": {
        "id": "sg8MQQsq-my4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Technology Type'].fillna(df['Technology Type'].mode()[0], inplace=True)\n",
        "df['Education Speaciality'].fillna(df['Education Speaciality'].mode()[0], inplace=True)\n",
        "df['Program Skill Level'].fillna(df['Program Skill Level'].mode()[0], inplace=True)\n",
        "df['Level of Education'].fillna(df['Level of Education'].mode()[0], inplace=True)\n",
        "df['Employment Status'].fillna(df['Employment Status'].mode()[0], inplace=True)\n",
        "\n",
        "df['Program Sub Category Code'].fillna(df['Program Main Category Code'], inplace=True)\n"
      ],
      "metadata": {
        "id": "jwdP3ziQYWm3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Program Start Date'] = pd.to_datetime(df['Program Start Date'])\n",
        "df['Program End Date'] = pd.to_datetime(df['Program End Date'])\n",
        "\n",
        "# Convert date columns to datetime\n",
        "date_columns = ['Program Start Date', 'Program End Date']\n",
        "df[date_columns] = df[date_columns].apply(pd.to_datetime)\n",
        "\n",
        "# Split date columns into separate day, month, and year columns for start and end dates\n",
        "df['Start Day'] = df['Program Start Date'].dt.day\n",
        "df['Start Month'] = df['Program Start Date'].dt.month\n",
        "df['Start Year'] = df['Program Start Date'].dt.year\n",
        "df['End Day'] = df['Program End Date'].dt.day\n",
        "df['End Month'] = df['Program End Date'].dt.month\n",
        "df['End Year'] = df['Program End Date'].dt.year\n",
        "\n",
        "df['Program Duration'] = (df['Program End Date'] - df['Program Start Date']).dt.days\n",
        "df['Start Quarter'] = df['Program Start Date'].dt.quarter\n",
        "df['End Quarter'] = df['Program End Date'].dt.quarter\n",
        "\n",
        "df.drop(columns=date_columns, inplace=True)"
      ],
      "metadata": {
        "id": "ydFxB-f1eWUx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TG56Hx0Z-5gh",
        "outputId": "7c236e35-b509-452b-ef5c-d79096765e1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Student ID                        0\n",
              "Age                               0\n",
              "Gender                            0\n",
              "Program ID                        0\n",
              "Program Main Category Code        0\n",
              "Program Sub Category Code         0\n",
              "Technology Type                   0\n",
              "Program Skill Level               0\n",
              "Program Presentation Method       0\n",
              "Program Days                      0\n",
              "Completed Degree                  0\n",
              "Level of Education                0\n",
              "Education Speaciality             0\n",
              "University Degree Score           0\n",
              "University Degree Score System    0\n",
              "Employment Status                 0\n",
              "Y                                 0\n",
              "Start Day                         0\n",
              "Start Month                       0\n",
              "Start Year                        0\n",
              "End Day                           0\n",
              "End Month                         0\n",
              "End Year                          0\n",
              "Program Duration                  0\n",
              "Start Quarter                     0\n",
              "End Quarter                       0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3- Model Building"
      ],
      "metadata": {
        "id": "ZA_fwABkZbp-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define features and target\n",
        "X = df.drop(['Y', 'Student ID'], axis=1)  # Exclude 'Y' and 'Student ID' from features\n",
        "y = df['Y']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Split categorical and numerical columns\n",
        "categorical_cols = X.select_dtypes(include=['object']).columns\n",
        "numerical_cols = X.select_dtypes(include=['number']).columns\n",
        "\n",
        "# Define the preprocessing steps for categorical and numerical features\n",
        "categorical_transformer = OneHotEncoder(handle_unknown='ignore')  # Encode categorical variables\n",
        "\n",
        "numerical_transformer = StandardScaler()  # Scale numerical features\n",
        "\n",
        "# Combine preprocessing steps for both categorical and numerical features\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', categorical_transformer, categorical_cols),\n",
        "        ('num', numerical_transformer, numerical_cols)\n",
        "    ])\n",
        "\n",
        "# Apply preprocessing to the data\n",
        "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
        "X_test_preprocessed = preprocessor.transform(X_test)\n",
        "\n",
        "# Train a logistic regression model\n",
        "logistic_model = LogisticRegression()\n",
        "logistic_model.fit(X_train_preprocessed, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_logistic = logistic_model.predict(X_test_preprocessed)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy_logistic = accuracy_score(y_test, y_pred_logistic)\n",
        "precision_logistic = precision_score(y_test, y_pred_logistic)\n",
        "recall_logistic = recall_score(y_test, y_pred_logistic)\n",
        "f1_logistic = f1_score(y_test, y_pred_logistic)\n",
        "\n",
        "# Print the results\n",
        "print(\"Logistic Regression:\")\n",
        "print(\"Accuracy:\", accuracy_logistic)\n",
        "print(\"Precision:\", precision_logistic)\n",
        "print(\"Recall:\", recall_logistic)\n",
        "print(\"F1 Score:\", f1_logistic)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFsFnEOQbDzp",
        "outputId": "79eab5b1-e302-4a0b-8e5e-942296804c62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression:\n",
            "Accuracy: 0.9015267175572519\n",
            "Precision: 0.6820809248554913\n",
            "Recall: 0.6145833333333334\n",
            "F1 Score: 0.6465753424657533\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4- Model Improvement"
      ],
      "metadata": {
        "id": "eeT_kFp5Zgah"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, recall_score\n",
        "\n",
        "# Define a dictionary of algorithms to try\n",
        "algorithms = {\n",
        "    'Logistic Regression': LogisticRegression(),\n",
        "    'Random Forest': RandomForestClassifier(),\n",
        "    'SVM': SVC(),\n",
        "    'Gradient Boosting': GradientBoostingClassifier()\n",
        "}\n",
        "\n",
        "best_model_name = ''\n",
        "best_model_score = 0.0\n",
        "\n",
        "# Iterate over each algorithm and evaluate its performance\n",
        "for algorithm_name, algorithm in algorithms.items():\n",
        "    # Define the preprocessing and modeling pipeline\n",
        "    pipeline = Pipeline([\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('model', algorithm)\n",
        "    ])\n",
        "\n",
        "        # Define the hyperparameter grid for grid search\n",
        "    param_grid = {}\n",
        "    if algorithm_name == 'Random Forest':\n",
        "        param_grid = {\n",
        "            'model__n_estimators': [100],\n",
        "            'model__max_depth': [None],\n",
        "            'model__min_samples_split': [2]\n",
        "        }\n",
        "    elif algorithm_name == 'SVM':\n",
        "        param_grid = {\n",
        "            'model__C': [1],\n",
        "            'model__kernel': ['linear']\n",
        "        }\n",
        "    elif algorithm_name == 'Gradient Boosting':\n",
        "        param_grid = {\n",
        "            'model__n_estimators': [100],\n",
        "            'model__learning_rate': [0.1],\n",
        "            'model__max_depth': [3]\n",
        "        }\n",
        "\n",
        "    # Perform grid search with cross-validation\n",
        "    grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy', refit=True)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    # Get the best model and its performance\n",
        "    best_model = grid_search.best_estimator_\n",
        "    cv_score = grid_search.best_score_\n",
        "\n",
        "    # Get the predictions for the test set\n",
        "    y_pred = best_model.predict(X_test)\n",
        "\n",
        "    # Calculate the F1 score and recall\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "\n",
        "    # Check if this model has the best score so far\n",
        "    if cv_score > best_model_score:\n",
        "        best_model_name = algorithm_name\n",
        "        best_model_score = cv_score\n",
        "\n",
        "    # Print the results for the current algorithm\n",
        "    print(algorithm_name)\n",
        "    print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
        "    print(\"CV Score:\", cv_score)\n",
        "    print(\"F1 Score:\", f1)\n",
        "    print(\"Recall:\", recall)\n",
        "    print(\"------------------------------------\")\n",
        "\n"
      ],
      "metadata": {
        "id": "9QWNPMXBXrRd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85c0ebe4-63e5-4552-a26d-b869a80d111a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression\n",
            "Best Hyperparameters: {}\n",
            "CV Score: 0.8835427648607072\n",
            "F1 Score: 0.6465753424657533\n",
            "Recall: 0.6145833333333334\n",
            "------------------------------------\n",
            "Random Forest\n",
            "Best Hyperparameters: {'model__max_depth': None, 'model__min_samples_split': 2, 'model__n_estimators': 100}\n",
            "CV Score: 0.8804891474733335\n",
            "F1 Score: 0.6306818181818181\n",
            "Recall: 0.578125\n",
            "------------------------------------\n",
            "SVM\n",
            "Best Hyperparameters: {'model__C': 1, 'model__kernel': 'linear'}\n",
            "CV Score: 0.8865983872496482\n",
            "F1 Score: 0.6361323155216285\n",
            "Recall: 0.6510416666666666\n",
            "------------------------------------\n",
            "Gradient Boosting\n",
            "Best Hyperparameters: {'model__learning_rate': 0.1, 'model__max_depth': 3, 'model__n_estimators': 100}\n",
            "CV Score: 0.8862165255874654\n",
            "F1 Score: 0.6528497409326426\n",
            "Recall: 0.65625\n",
            "------------------------------------\n"
          ]
        }
      ]
    }
  ]
}